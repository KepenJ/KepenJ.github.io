<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Scrapy 爬虫学习中不可或缺的利器 | Log'K'</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Scrapy 爬虫学习中不可或缺的利器</h1><a id="logo" href="/.">Log'K'</a><p class="description">Learn more.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Scrapy 爬虫学习中不可或缺的利器</h1><div class="post-meta">Oct 22, 2015<span> | </span><span class="category"><a href="/categories/Python/">Python</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="http://www.kepenj.me/blog/2015/09/28/wan-zhao-pa-chong-xue-python-(san-/" target="_blank" rel="external">Python 爬虫学习（三）</a>中我们完成了通过百度贴吧爬虫的例子来入门我们针对无论 Python 还是爬虫的入门学习。在接下来这篇当中，我们将针对更高层方面的框架和实际生产环境方面的爬虫进行学习研究。</p>
<h2 id="爬虫利器-——-Scrapy"><a href="#爬虫利器-——-Scrapy" class="headerlink" title="爬虫利器 —— Scrapy"></a>爬虫利器 —— Scrapy</h2><p><a href="http://scrapy.org/" target="_blank" rel="external">Scrapy</a>是一个快速、可扩展，用于处理网络信息或者资源摘取，使用 Python 语言所写的开源的框架。在这里有一个 <a href="http://scrapy-chs.readthedocs.org/zh_CN/latest/intro/overview.html" target="_blank" rel="external">Scrapy 中文文档</a>可以做很好的参照和讲解。</p>
<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>要想能正常使用 Scrapy 框架，还需要解决 Scrapy 的一下几方面依赖：</p>
<ol>
<li>Python2.7，Scrapy 现在还不支持 3.0 以上的 Python 版本（官网上显示还正在兼容中，这点也让人很惆怅）。</li>
<li>pip 安装，官网上推荐开发者通过 pip 来完成 Scrapy的安装。</li>
<li>lxml的支持，在安装这个库的时候，po遇到了问题。（相关细节po主会在之后的章节进行表述）。</li>
<li>OpenSSL基于加密传输的一个库。</li>
</ol>
<p>如果你以上4个依赖你都已经处理好了，那么你只需要在中断输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install scrapy</div></pre></td></tr></table></figure>
<p>命令来运行了。</p>
<h3 id="配置环境时遇到的问题"><a href="#配置环境时遇到的问题" class="headerlink" title="配置环境时遇到的问题"></a>配置环境时遇到的问题</h3><p>po主在配置 Scrapy 的环境中就遇到了问题。在安装 <a href="http://lxml.de/" target="_blank" rel="external">lxml</a> 的时候，并没有预期那样success，而是爆出了error</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#include &quot;libxml/xmlversion.h&quot;</div><div class="line"></div><div class="line">     ^</div><div class="line">1 error generated.</div><div class="line">error: command &apos;cc&apos; failed with exit status 1</div></pre></td></tr></table></figure>
<p>还是在<a href="file:///Users/kepenj/Desktop/KepenJ.github.io-master/2015/10/22/2015-10-22-wan-zhao-pa-chong-xue-python-(si-" target="_blank" rel="external">C_INCLUDE_PATH 指定到 XCode MacOSX SDK 中 libxml 路径一贴</a>/index.html)里面找到了解决方案，修改了 pip 安装时将原本 pip 中依赖的 xmlversion.h 的路径修改成下面这个路径，然后在执行 <code>pip install lxml</code> 安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudu C_INCLUDE_PATH=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/usr/include/libxml2/libxml/xmlversion.h pip install lxml</div></pre></td></tr></table></figure>
<p>另一个则是 <code>six</code> 这个库的问题，当po🐷满心欢喜的准备开始第一个 Scrapy 程序的时候总是事与愿违</p>
<p><img src="https://raw.githubusercontent.com/KepenJ/BlogImages/master/python_4/5.png" alt="1.1"></p>
<p>同样在 <a href="http://stackoverflow.com/questions/30964836/scrapy-throws-importerror-cannot-import-name-xmlrpc-client" target="_blank" rel="external">stackoverflow上面</a>解决了，结果就是我们卸载 six 这个库然后在重新安装即可。</p>
<h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><p>说完了环境配置，来聊聊 Scrapy 相关细节介绍，下图是这个库的架构图：</p>
<p><img src="https://raw.githubusercontent.com/KepenJ/BlogImages/master/python_4/4.png" alt="1.2"></p>
<p>整个 Scrapy 框架包含了：</p>
<ol>
<li>调度（Scheduler），也就是接收过来的请求。</li>
<li>下载器（Downloader），执行我们的请求并接收我们的返回结果。</li>
<li>爬虫（Spiders），我们核心的抓取、解析规则的载体。</li>
<li>项目管理（Item Pipeline），结果的处理、过滤和存储的载体。</li>
</ol>
<p>这些模块之间的相连和循环总体组成了整个 Scrapy ，更多相关框架介绍可以参照<a href="http://www.360doc.com/content/14/0325/22/9482_363730690.shtml" target="_blank" rel="external">这篇文章</a>。</p>
<p>下来我们建立 Scrapy 的项目</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scrapy startproject MyScrapy</div></pre></td></tr></table></figure>
<p>项目的结构图如下：</p>
<p><img src="https://raw.githubusercontent.com/KepenJ/BlogImages/master/python_4/6.png" alt="1.3"></p>
<p>相关介绍如下：</p>
<ul>
<li>scrapy.cfg: 项目的配置文件。</li>
<li>MyScrapy/: 该项目的python模块。之后您将在此加入代码。</li>
<li>MyScrapy/items.py: 项目中的item文件。</li>
<li>MyScrapy/pipelines.py: 项目中的pipelines文件。</li>
<li>MyScrapy/settings.py: 项目的设置文件。</li>
<li>MyScrapy/spiders/: 放置spider代码的目录。</li>
</ul>
<p>在这里我们运用 Scrapy 文档中的例子 来讲解 Scarpy 爬虫，首先还是上我们的源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozSpider</span><span class="params">(scrapy.spiders.Spider)</span>:</span></div><div class="line">    name = <span class="string">"dmoz"</span></div><div class="line">    allowed_domains = [<span class="string">"dmoz.org"</span>]</div><div class="line">    start_urls = [</div><div class="line">        <span class="string">"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span>,</div><div class="line">        <span class="string">"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"</span></div><div class="line">    ]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></div><div class="line">        filename = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</div><div class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">            f.write(response.body)</div></pre></td></tr></table></figure>
<p>首先我们的爬虫存放于<code>MyScrapy/spiders/</code>目录下，同时爬虫对象需要继承 <code>scrapy.spiders.Spider</code> ，同时实现 <code>name</code> 、 <code>allowed_domains</code> 和 <code>start_urls</code> 这三个参数设置，还有 <code>parse()</code> 这个回调函数。他们的作用分别是：</p>
<ul>
<li>name 用来表明你这个爬虫的名称。</li>
<li>allowed_domains 用来划分你所爬网站的域名范围，目的是防止爬虫爬到其他域名链接里面去了。</li>
<li>start_urls 就是来明确我们所要扒取的起始url位置。</li>
<li>parse() 当我们请求成功回调的 response 就会到这个函数中去执行我们所要的逻辑，当然上面这个例子就仅仅是做了简单的文件存储。</li>
</ul>
<p>依旧通过命令行，当然你需要在你项目的根目录下运行这条指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scrapy crawl dmoz</div></pre></td></tr></table></figure>
<p>结果如下图</p>
<p><img src="https://raw.githubusercontent.com/KepenJ/BlogImages/master/python_4/7.png" alt="1.4"></p>
<p>其中 <code>Books</code> 和 <code>Resources</code> 就是我们抓下来的数据。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇只是针对 Scrapy 框架的介绍和简单用法。因为最近项目太忙的缘故，下一片针对 Scrapy 案例的学习总结可能会稍微慢些（po🐷顺带也得去好好恶补正则表达式了…逃）。好吧，那这篇就到这了…(这次就让我划个水好了 <em>(:з」∠)</em> )</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2015/10/22/Scrapy-爬虫学习中不可或缺的利器/" data-id="cis7dlg1n000bmmu500k3pxr6" class="article-share-link">分享到</a><div class="tags"></div><div class="post-nav"><a href="/2015/12/29/2015-终总结和-2016-的-flag/" class="pre">2015 终总结和 2016 的 flag</a><a href="/2015/09/28/Python-爬虫学习（三）/" class="next">Python 爬虫学习（三）</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/iOS/">iOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂感/">杂感</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/02/21/Apple-pay-体验报告/">Apple pay 体验报告</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/29/2015-终总结和-2016-的-flag/">2015 终总结和 2016 的 flag</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/10/22/Scrapy-爬虫学习中不可或缺的利器/">Scrapy 爬虫学习中不可或缺的利器</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/28/Python-爬虫学习（三）/">Python 爬虫学习（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/18/Python-爬虫学习（二）/">Python 爬虫学习（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/16/Python-爬虫学习（一）/">Python 爬虫学习（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/06/深入了解-iOS-中的-Block/">深入了解 iOS 中的 Block</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/08/20/在这个特殊的日子，我们来聊聊-KVO-吧/">在这个特殊的日子，我们来聊聊 KVO 吧</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/08/18/CodeSign和App的爱恨情仇/">CodeSign和App的爱恨情仇</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/08/06/iOS补漏和拾遗，从BAT的面试题出发（二）/">iOS补漏和拾遗，从BAT的面试题出发（二）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/KepenJ" title="Github" target="_blank">Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Log'K'.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>